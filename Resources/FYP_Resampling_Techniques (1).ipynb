{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3175,"status":"ok","timestamp":1661229071690,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"WTKuXyY6ap9B","outputId":"25d277a5-d033-48f2-c33b-5cef51f60420"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":452,"status":"ok","timestamp":1661229073741,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"YjDG6JhCcd6L"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl \n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"OFauFJz0b4BX"},"source":[""]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":2124,"status":"ok","timestamp":1661229176444,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"VaJjHBdNcoXI","outputId":"9aa2f0a4-6685-4da0-a48a-01c2cce8fd54"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-fc0390f8-97ba-4874-adfa-d022c0fbc541\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.1\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.2\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.3\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.4\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.5\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.6\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.7\u003c/th\u003e\n","      \u003cth\u003eX2005_exp1_allign\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e6.168618e+03\u003c/td\u003e\n","      \u003ctd\u003e7647.498535\u003c/td\u003e\n","      \u003ctd\u003e8.915109e+03\u003c/td\u003e\n","      \u003ctd\u003e8.566661e+03\u003c/td\u003e\n","      \u003ctd\u003e8.778825e+03\u003c/td\u003e\n","      \u003ctd\u003e13387.581055\u003c/td\u003e\n","      \u003ctd\u003e5.873571e+03\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e-1.047208e+07\u003c/td\u003e\n","      \u003ctd\u003e21917.025391\u003c/td\u003e\n","      \u003ctd\u003e-7.160036e+06\u003c/td\u003e\n","      \u003ctd\u003e1.784593e+04\u003c/td\u003e\n","      \u003ctd\u003e-2.813916e+07\u003c/td\u003e\n","      \u003ctd\u003e23548.406250\u003c/td\u003e\n","      \u003ctd\u003e-8.029225e+06\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1.209632e+04\u003c/td\u003e\n","      \u003ctd\u003e9733.765625\u003c/td\u003e\n","      \u003ctd\u003e1.403009e+04\u003c/td\u003e\n","      \u003ctd\u003e1.835059e+04\u003c/td\u003e\n","      \u003ctd\u003e8.439968e+03\u003c/td\u003e\n","      \u003ctd\u003e19418.904297\u003c/td\u003e\n","      \u003ctd\u003e1.378371e+04\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e-2.899898e+07\u003c/td\u003e\n","      \u003ctd\u003e-586623.812500\u003c/td\u003e\n","      \u003ctd\u003e-2.847262e+07\u003c/td\u003e\n","      \u003ctd\u003e-1.391462e+07\u003c/td\u003e\n","      \u003ctd\u003e-3.322891e+07\u003c/td\u003e\n","      \u003ctd\u003e16535.669922\u003c/td\u003e\n","      \u003ctd\u003e-4.535712e+07\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e-1.592751e+07\u003c/td\u003e\n","      \u003ctd\u003e25672.757812\u003c/td\u003e\n","      \u003ctd\u003e-1.337754e+07\u003c/td\u003e\n","      \u003ctd\u003e1.940432e+04\u003c/td\u003e\n","      \u003ctd\u003e-2.681462e+07\u003c/td\u003e\n","      \u003ctd\u003e22352.603516\u003c/td\u003e\n","      \u003ctd\u003e-2.740977e+07\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc0390f8-97ba-4874-adfa-d022c0fbc541')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-fc0390f8-97ba-4874-adfa-d022c0fbc541 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc0390f8-97ba-4874-adfa-d022c0fbc541');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   Unnamed: 0  modisCropF3_ESTARFM.1  modisCropF3_ESTARFM.2  \\\n","0           1           6.168618e+03            7647.498535   \n","1           2          -1.047208e+07           21917.025391   \n","2           3           1.209632e+04            9733.765625   \n","3           4          -2.899898e+07         -586623.812500   \n","4           5          -1.592751e+07           25672.757812   \n","\n","   modisCropF3_ESTARFM.3  modisCropF3_ESTARFM.4  modisCropF3_ESTARFM.5  \\\n","0           8.915109e+03           8.566661e+03           8.778825e+03   \n","1          -7.160036e+06           1.784593e+04          -2.813916e+07   \n","2           1.403009e+04           1.835059e+04           8.439968e+03   \n","3          -2.847262e+07          -1.391462e+07          -3.322891e+07   \n","4          -1.337754e+07           1.940432e+04          -2.681462e+07   \n","\n","   modisCropF3_ESTARFM.6  modisCropF3_ESTARFM.7  X2005_exp1_allign  \n","0           13387.581055           5.873571e+03                  1  \n","1           23548.406250          -8.029225e+06                  1  \n","2           19418.904297           1.378371e+04                  1  \n","3           16535.669922          -4.535712e+07                  1  \n","4           22352.603516          -2.740977e+07                  1  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/content/drive/MyDrive/down_sampled.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"l1RfuzyG8FnL"},"source":["# New Section"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":440,"status":"ok","timestamp":1661229187531,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"O2HTWVM1cq83","outputId":"fa6648d8-9926-4b68-b1c7-e5a94a72da8f"},"outputs":[{"data":{"text/plain":["(89887, 9)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"7OEn7fkcgult"},"source":["# **Scaling of the Data**"]},{"cell_type":"markdown","metadata":{"id":"iJ8KxUtGhKQ3"},"source":["Standard Scaler =\u003e (x-mean)/std"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":441,"status":"ok","timestamp":1661229239144,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"Xdw3bBVMgkre"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8KnQzQDhTGn"},"outputs":[],"source":["scaler = StandardScaler()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1661229291096,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"i1WLw4YXmTBK","outputId":"a2ca6fb8-10c2-4c38-cbb9-3e3221dc119f"},"outputs":[{"data":{"text/plain":["(89887, 8)"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data = df.drop(['X2005_exp1_allign'],axis = 1)\n","data.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":437,"status":"ok","timestamp":1661229296373,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"hvShb_FqltPN"},"outputs":[],"source":["X = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1661229300158,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"yFuvLYoultMH","outputId":"51c5bdc4-c85c-48ae-b8a4-0578f442da95"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-3cd7a4b0-14c5-4506-aa0e-93b14a40f1f1\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eUnnamed: 0\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.1\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.2\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.3\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.4\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.5\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.6\u003c/th\u003e\n","      \u003cth\u003emodisCropF3_ESTARFM.7\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e6.168618e+03\u003c/td\u003e\n","      \u003ctd\u003e7647.498535\u003c/td\u003e\n","      \u003ctd\u003e8.915109e+03\u003c/td\u003e\n","      \u003ctd\u003e8.566661e+03\u003c/td\u003e\n","      \u003ctd\u003e8.778825e+03\u003c/td\u003e\n","      \u003ctd\u003e13387.581055\u003c/td\u003e\n","      \u003ctd\u003e5.873571e+03\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e-1.047208e+07\u003c/td\u003e\n","      \u003ctd\u003e21917.025391\u003c/td\u003e\n","      \u003ctd\u003e-7.160036e+06\u003c/td\u003e\n","      \u003ctd\u003e1.784593e+04\u003c/td\u003e\n","      \u003ctd\u003e-2.813916e+07\u003c/td\u003e\n","      \u003ctd\u003e23548.406250\u003c/td\u003e\n","      \u003ctd\u003e-8.029225e+06\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1.209632e+04\u003c/td\u003e\n","      \u003ctd\u003e9733.765625\u003c/td\u003e\n","      \u003ctd\u003e1.403009e+04\u003c/td\u003e\n","      \u003ctd\u003e1.835059e+04\u003c/td\u003e\n","      \u003ctd\u003e8.439968e+03\u003c/td\u003e\n","      \u003ctd\u003e19418.904297\u003c/td\u003e\n","      \u003ctd\u003e1.378371e+04\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e-2.899898e+07\u003c/td\u003e\n","      \u003ctd\u003e-586623.812500\u003c/td\u003e\n","      \u003ctd\u003e-2.847262e+07\u003c/td\u003e\n","      \u003ctd\u003e-1.391462e+07\u003c/td\u003e\n","      \u003ctd\u003e-3.322891e+07\u003c/td\u003e\n","      \u003ctd\u003e16535.669922\u003c/td\u003e\n","      \u003ctd\u003e-4.535712e+07\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e5\u003c/td\u003e\n","      \u003ctd\u003e-1.592751e+07\u003c/td\u003e\n","      \u003ctd\u003e25672.757812\u003c/td\u003e\n","      \u003ctd\u003e-1.337754e+07\u003c/td\u003e\n","      \u003ctd\u003e1.940432e+04\u003c/td\u003e\n","      \u003ctd\u003e-2.681462e+07\u003c/td\u003e\n","      \u003ctd\u003e22352.603516\u003c/td\u003e\n","      \u003ctd\u003e-2.740977e+07\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd7a4b0-14c5-4506-aa0e-93b14a40f1f1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-3cd7a4b0-14c5-4506-aa0e-93b14a40f1f1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3cd7a4b0-14c5-4506-aa0e-93b14a40f1f1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["   Unnamed: 0  modisCropF3_ESTARFM.1  modisCropF3_ESTARFM.2  \\\n","0           1           6.168618e+03            7647.498535   \n","1           2          -1.047208e+07           21917.025391   \n","2           3           1.209632e+04            9733.765625   \n","3           4          -2.899898e+07         -586623.812500   \n","4           5          -1.592751e+07           25672.757812   \n","\n","   modisCropF3_ESTARFM.3  modisCropF3_ESTARFM.4  modisCropF3_ESTARFM.5  \\\n","0           8.915109e+03           8.566661e+03           8.778825e+03   \n","1          -7.160036e+06           1.784593e+04          -2.813916e+07   \n","2           1.403009e+04           1.835059e+04           8.439968e+03   \n","3          -2.847262e+07          -1.391462e+07          -3.322891e+07   \n","4          -1.337754e+07           1.940432e+04          -2.681462e+07   \n","\n","   modisCropF3_ESTARFM.6  modisCropF3_ESTARFM.7  \n","0           13387.581055           5.873571e+03  \n","1           23548.406250          -8.029225e+06  \n","2           19418.904297           1.378371e+04  \n","3           16535.669922          -4.535712e+07  \n","4           22352.603516          -2.740977e+07  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["X.head()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1661229314669,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"j0qrBbl4ltKH","outputId":"7ba14157-1497-480c-b41c-27f1febd405c"},"outputs":[{"data":{"text/plain":["0         1\n","1         1\n","2         1\n","3         1\n","4         1\n","         ..\n","89882    15\n","89883    15\n","89884    15\n","89885    15\n","89886    15\n","Name: X2005_exp1_allign, Length: 89887, dtype: int64"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["y = df['X2005_exp1_allign']\n","y"]},{"cell_type":"markdown","metadata":{"id":"EVzw0Z7rm_z8"},"source":["# **Sampling Techniques**"]},{"cell_type":"markdown","metadata":{"id":"5B6keAHaum_0"},"source":["# **SMOTE**"]},{"cell_type":"markdown","metadata":{"id":"gR55o8hRtSpU"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"fCxSuZVntT4l"},"source":["# New Section"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":494,"status":"ok","timestamp":1661229321876,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"rRqrfLTEjTRO"},"outputs":[],"source":["from imblearn.over_sampling import SMOTE\n","\n","smote = SMOTE()\n","x_smote, y_smote = smote.fit_resample(X, y)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661229327397,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"LkvnxsmOuxVM","outputId":"ae233eea-747d-4d36-9530-309937618a7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape Counter({1: 12841, 2: 12841, 3: 12841, 7: 12841, 9: 12841, 10: 12841, 15: 12841})\n","Resample dataset shape Counter({1: 12841, 2: 12841, 3: 12841, 7: 12841, 9: 12841, 10: 12841, 15: 12841})\n"]}],"source":["from collections import Counter\n","\n","print('Original dataset shape', Counter(y))\n","print('Resample dataset shape', Counter(y_smote))"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":429,"status":"ok","timestamp":1661229334355,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"Zy5wd23uvIfx"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1661229339082,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"vyQSsBht5ee4"},"outputs":[],"source":["def measure(model,X, Y):\n","  from sklearn.metrics import make_scorer\n","  \n","  accuracy = cross_val_score(model, X, Y, scoring ='accuracy', cv = 10)\n","  precision = cross_val_score(model, X, Y, scoring = 'precision', cv = 10)\n","  recall = cross_val_score(model, X, Y, scoring = 'recall', cv = 10)\n","  F1 = cross_val_score(model, X, Y, scoring = 'f1', cv = 10)\n","\n","  sol = []\n","  sol.append(accuracy.mean())\n","  sol.append(precision.mean())\n","  sol.append(recall.mean())\n","  sol.append(F1.mean())\n","\n","  return sol"]},{"cell_type":"markdown","metadata":{"id":"-SrW-tTi5e-7"},"source":["def measure(model,X, Y):\n","\n","  accuracy = cross_val_score(model, X, Y, scoring='accuracy', cv = 10)\n","\n","  precision = cross_val_score(model, X, Y, scoring='precision', cv = 10)\n","\n","  recall = cross_val_score(model, X, Y, scoring='recall', cv = 10)\n","\n","  F1 = cross_val_score(model, X, Y, scoring='f1', cv = 10)\n","\n","  sol = []\n","  sol.append(accuracy.mean())\n","  sol.append(precision.mean())\n","  sol.append(recall.mean())\n","  sol.append(F1.mean())\n","\n","  return sol\n"]},{"cell_type":"markdown","metadata":{"id":"T0cOAl-kvnq3"},"source":["**SMOTE using Logistic Regression**"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1661229345873,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"WrJ1UhHUrLMa"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351879,"status":"ok","timestamp":1661229700222,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"6--O0Zh2r-s8","outputId":"6a148aa5-1e87-493b-9a3f-c0569e97546b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and Logistic Regression is :  25.4942\n","Precision using SMOTE and Logistic Regression is :  nan\n","Recall using SMOTE and Logistic Regression is :  nan\n","F1 Score using SMOTE and Logistic Regression is :  nan\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]}],"source":["ans = measure(log, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"gHebNFmqvqpv"},"source":["**SMOTE using Decision Tree**"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":495,"status":"ok","timestamp":1661232837986,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"ZdRA56YxvkO8"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17122,"status":"ok","timestamp":1661232857975,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"yY8EpTQEs2Rc","outputId":"0105779c-0087-4ec4-fa42-5843da45e4e6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and Decision Tree is :  91.429\n","Precision using SMOTE and Decision Tree is :  nan\n","Recall using SMOTE and Decision Tree is :  nan\n","F1 Score using SMOTE and Decision Tree is :  nan\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]}],"source":["ans = measure(clf, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"tOX2flvaxDCJ"},"source":["**SMOTE using SVM**"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":458,"status":"ok","timestamp":1661232913396,"user":{"displayName":"Bharathi D","userId":"03025041540859333869"},"user_tz":-330},"id":"Sp3JNbR9v_Si"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"aNsHAqtctEjw"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1909, in recall_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and SVM is :  36.6282\n","Precision using SMOTE and SVM is :  nan\n","Recall using SMOTE and SVM is :  nan\n","F1 Score using SMOTE and SVM is :  nan\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n","    scores = scorer(estimator, X_test, y_test)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n","    score = scorer._score(cached_call, estimator, *args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n","    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1131, in f1_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n","    zero_division=zero_division,\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n","    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1367, in _check_set_wise_labels\n","    \"choose another average setting, one of %r.\" % (y_type, average_options)\n","ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n","\n","  UserWarning,\n"]}],"source":["ans = measure(cl, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"nz_eA9vpxyog"},"source":["**SMOTE using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4ORMTqMxBBM"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1291,"status":"ok","timestamp":1638173692272,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"eJtRpdtftPD2","outputId":"cd8d0d07-2709-4af5-d095-97a4c63a5840"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and Naive Bayes is :  81.4286\n","Precision using SMOTE and Naive Bayes is :  91.2381\n","Recall using SMOTE and Naive Bayes is :  70.0\n","F1 Score using SMOTE and Naive Bayes is :  78.1262\n"]}],"source":["ans = measure(gnb, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"cXRDx1VQyh3i"},"source":["**SMOTE using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4a9KhkGxxdR"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(random_state=0) #max_depth=2,"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8347,"status":"ok","timestamp":1638173710526,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"7s2mjMy9trel","outputId":"ee4b8970-8949-4918-a57f-1fff884cce2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and Random Forest is :  83.5714\n","Precision using SMOTE and Random Forest is :  87.5\n","Recall using SMOTE and Random Forest is :  80.0\n","F1 Score using SMOTE and Random Forest is :  82.7343\n"]}],"source":["ans = measure(rf, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"qQ7bXneurPKK"},"source":["**SMOTE using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpZXHTFhyfCT"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2607,"status":"ok","timestamp":1638173721161,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"9oPOGAmrt7My","outputId":"81dac1e7-68b7-425a-f69e-105ae0131582"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using SMOTE and KNN is :  74.2857\n","Precision using SMOTE and KNN is :  83.5714\n","Recall using SMOTE and KNN is :  54.2857\n","F1 Score using SMOTE and KNN is :  64.4875\n"]}],"source":["ans = measure(knn, x_smote, y_smote)\n","\n","print(\"Acuracy using SMOTE and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using SMOTE and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using SMOTE and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using SMOTE and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"pzRlRvCFzibr"},"source":["# **Random Under Sampling with Imblearn**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEsgS15TzAEb"},"outputs":[],"source":["from imblearn.under_sampling import RandomUnderSampler\n","\n","rus = RandomUnderSampler(random_state=42, replacement=True)\n","x_rus, y_rus = rus.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1638173729739,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"Pe9SbPZ1zfdN","outputId":"a51a0515-8784-46cd-eef1-71cd310e90bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape Counter({0: 31, 1: 31})\n"]}],"source":["print('original dataset shape:', Counter(y))\n","print('Resample dataset shape', Counter(y_rus))"]},{"cell_type":"markdown","metadata":{"id":"iXO0r7-UqLo_"},"source":["**Random Undersampling with Imblearn using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L3CIzbzqzxTh"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2893,"status":"ok","timestamp":1638173734834,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"3kRmC05PuKY3","outputId":"7f91da0e-f7ff-47fb-abc8-2cf25ade3bf1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Logistic Regression is :  65.0\n","Precision using Random Undersampling - Imblearn and Logistic Regression is :  64.1667\n","Recall using Random Undersampling - Imblearn and Logistic Regression is :  68.3333\n","F1 Score using Random Undersampling - Imblearn and Logistic Regression is :  65.6667\n"]}],"source":["ans = measure(log, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"kSMpAyYzqhJ3"},"source":["**Random Undersampling with Imblearn using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLn5-32QqJlP"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":451,"status":"ok","timestamp":1638173745148,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"1mo0Iw_Kuamz","outputId":"44d55168-6ad9-4c69-8641-d4baedad5aea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Decision Tree is :  68.8095\n","Precision using Random Undersampling - Imblearn and Decision Tree is :  74.8333\n","Recall using Random Undersampling - Imblearn and Decision Tree is :  80.0\n","F1 Score using Random Undersampling - Imblearn and Decision Tree is :  73.4365\n"]}],"source":["ans = measure(clf, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Qf0BFmG0qzDQ"},"source":["**Random Undersampling with Imblearn using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8P22KhBeqfB1"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":657,"status":"ok","timestamp":1638173750195,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"RckzQ1Cuuo3P","outputId":"43e70f04-2cb9-427e-bd31-3f0a5b73e3df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and SVM is :  60.0\n","Precision using Random Undersampling - Imblearn and SVM is :  59.1667\n","Recall using Random Undersampling - Imblearn and SVM is :  55.0\n","F1 Score using Random Undersampling - Imblearn and SVM is :  54.6667\n"]}],"source":["ans = measure(cl, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Q4zo8gT7rHqP"},"source":["**Random Undersampling with Imblearn using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfwZWTsWqx7Q"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1854,"status":"ok","timestamp":1638173756268,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"9XfWE5qnuytx","outputId":"f60624ba-a972-4cdc-ed47-c820060c7bab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Naive Bayes is :  63.3333\n","Precision using Random Undersampling - Imblearn and Naive Bayes is :  70.8333\n","Recall using Random Undersampling - Imblearn and Naive Bayes is :  58.3333\n","F1 Score using Random Undersampling - Imblearn and Naive Bayes is :  60.3333\n"]}],"source":["ans = measure(gnb, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"IMD0eTrnrdLb"},"source":["**Random Undersampling with Imblearn using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Ft6RlI1rGs5"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6831,"status":"ok","timestamp":1638173769488,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"hpduuy_UvBYs","outputId":"29a9eda2-c60b-4a09-daad-c2a80050e420"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Random Forest is :  73.0952\n","Precision using Random Undersampling - Imblearn and Random Forest is :  73.3333\n","Recall using Random Undersampling - Imblearn and Random Forest is :  80.8333\n","F1 Score using Random Undersampling - Imblearn and Random Forest is :  75.8571\n"]}],"source":["ans = measure(rf, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"jOxvaZyxrrHL"},"source":["**Random Undersampling with Imblearn using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leox3oenrcev"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1311,"status":"ok","timestamp":1638173776138,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"JnyQAZaBvQGn","outputId":"2d36261d-85ad-46b7-afff-97d109e079f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and KNN is :  63.5714\n","Precision using Random Undersampling - Imblearn and KNN is :  61.6667\n","Recall using Random Undersampling - Imblearn and KNN is :  69.1667\n","F1 Score using Random Undersampling - Imblearn and KNN is :  64.2857\n"]}],"source":["ans = measure(knn, x_rus, y_rus)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Y6z_WF4qsCr8"},"source":["# **Undersampling Tomek Links**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BJ1E-BOr-6o"},"outputs":[],"source":["from imblearn.under_sampling import TomekLinks\n","\n","undersample = TomekLinks()\n","x_tl, y_tl = undersample.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1638173783308,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"hoi-1bCrsMhW","outputId":"f2e5b674-e8c2-4de6-d8bf-956a6bb5819a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape Counter({1: 70, 0: 31})\n","Resample dataset shape Counter({1: 65, 0: 31})\n"]}],"source":["from collections import Counter\n","\n","print('Original dataset shape', Counter(y))\n","print('Resample dataset shape', Counter(y_tl))"]},{"cell_type":"markdown","metadata":{"id":"PYwvm2chsnTu"},"source":["**Undersampling with Tomek Links using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fKjJ1CGksPE4"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1638173791258,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"Bfdh3ddiyjF4","outputId":"2d863261-7c97-4182-e679-00290f8fb92b"},"outputs":[{"data":{"text/plain":["0     1\n","1     1\n","2     1\n","3     1\n","4     1\n","     ..\n","91    0\n","92    0\n","93    0\n","94    0\n","95    0\n","Name: labels, Length: 96, dtype: int64"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["y_tl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1959,"status":"ok","timestamp":1638173796616,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"rMhEXdzFvZWf","outputId":"18fa876c-47ed-46f2-e670-7e0619e7947d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Undersampling Tomek Links and Logistic Regression is :  65.5556\n","Precision using Undersampling Tomek Links and Logistic Regression is :  67.8373\n","Recall using Undersampling Tomek Links and Logistic Regression is :  93.8095\n","F1 Score using Undersampling Tomek Links and Logistic Regression is :  78.5558\n"]}],"source":["ans = measure(log, x_tl, y_tl)\n","\n","print(\"Acuracy using Undersampling Tomek Links and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Undersampling Tomek Links and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Undersampling Tomek Links and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Undersampling Tomek Links and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"E_7HF-s4s6c5"},"source":["**Undersampling with Tomek Links using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LesYNip2sk6V"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1489,"status":"ok","timestamp":1638173805549,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"5vOfFtHOzZNi","outputId":"59fba6e2-90fc-47e5-e3f2-f80f3b297eda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Undersampling Tomek Links and Decision Tree is :  63.6667\n","Precision using Undersampling Tomek Links and Decision Tree is :  72.6905\n","Recall using Undersampling Tomek Links and Decision Tree is :  71.1905\n","F1 Score using Undersampling Tomek Links and Decision Tree is :  70.0793\n"]}],"source":["ans = measure(clf, x_tl, y_tl)\n","\n","print(\"Acuracy using Undersampling Tomek Links and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Undersampling Tomek Links and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Undersampling Tomek Links and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Undersampling Tomek Links and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Q6EFLmTit4dB"},"source":["**Undersampling with Tomek Links using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlBQPASvs5FX"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1580,"status":"ok","timestamp":1638173810497,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"zi9Z0xFzz4sk","outputId":"02b7aef8-b428-44bb-da0d-1f00833c4701"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Undersampling Tomek Links and SVM is :  67.6667\n","Precision using Undersampling Tomek Links and SVM is :  67.6667\n","Recall using Undersampling Tomek Links and SVM is :  100.0\n","F1 Score using Undersampling Tomek Links and SVM is :  80.6765\n"]}],"source":["ans = measure(cl, x_tl, y_tl)\n","\n","print(\"Acuracy using Undersampling Tomek Links and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Undersampling Tomek Links and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Undersampling Tomek Links and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Undersampling Tomek Links and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"5nEiQA-7uKRU"},"source":["**Undersampling with Tomek Links using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXSONjiYt28G"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1147,"status":"ok","timestamp":1638173815478,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"amb5calD0iUj","outputId":"7b82e963-9fe9-400f-ee73-216a247d9606"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Naive Bayes is :  68.1111\n","Precision using Random Undersampling - Imblearn and Naive Bayes is :  81.0952\n","Recall using Random Undersampling - Imblearn and Naive Bayes is :  71.6667\n","F1 Score using Random Undersampling - Imblearn and Naive Bayes is :  74.5694\n"]}],"source":["ans = measure(gnb, x_tl, y_tl)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"1zAWEjtcugXU"},"source":["**Undersampling with Tomek Links using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZehEp7SwuJLy"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8654,"status":"ok","timestamp":1638173831162,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"4WaIdP0j0rob","outputId":"3d7ecfce-0504-4255-f85b-9fef545c4f63"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and Random Forest is :  70.7778\n","Precision using Random Undersampling - Imblearn and Random Forest is :  72.7817\n","Recall using Random Undersampling - Imblearn and Random Forest is :  92.1429\n","F1 Score using Random Undersampling - Imblearn and Random Forest is :  80.9752\n"]}],"source":["ans = measure(rf, x_tl, y_tl)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"w8swiuekuy7a"},"source":["**Undersampling with Tomek Links using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Fa_RjL7ufgv"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1299,"status":"ok","timestamp":1638173837554,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"5nA-A7Ll0y_Y","outputId":"95e6a038-2f86-4446-c7c3-e9f25d539ef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling - Imblearn and KNN is :  62.5556\n","Precision using Random Undersampling - Imblearn and KNN is :  70.5952\n","Recall using Random Undersampling - Imblearn and KNN is :  78.5714\n","F1 Score using Random Undersampling - Imblearn and KNN is :  73.6832\n"]}],"source":["ans = measure(knn, x_tl, y_tl)\n","\n","print(\"Acuracy using Random Undersampling - Imblearn and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling - Imblearn and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling - Imblearn and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling - Imblearn and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"JXlzOgrTvLf5"},"source":["# **Condensed Nearest Neighbor(CNN) Rule**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cB1ohwAPuyEj"},"outputs":[],"source":["from imblearn.under_sampling import CondensedNearestNeighbour\n","\n","from warnings import simplefilter\n","simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1638173845053,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"dYfpy5cEvWYK","outputId":"c6088f48-2d0c-416f-ee39-a440adb42884"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape Counter({1: 70, 0: 31})\n","Resample dataset shape Counter({1: 37, 0: 31})\n"]}],"source":["condense = CondensedNearestNeighbour(n_neighbors=2)\n","x_condense,y_condense = condense.fit_resample(X,y)\n","\n","print('Original dataset shape', Counter(y))\n","print('Resample dataset shape', Counter(y_condense))"]},{"cell_type":"markdown","metadata":{"id":"nd5635ntwJ59"},"source":["**Condensed Nearest Neighbor using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNQfQpoZvZ4m"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1515,"status":"ok","timestamp":1638173853133,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"yqS7KgYp0-tK","outputId":"b7449283-054f-49ef-ca44-68e54ca202af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and Logistic Regression is :  59.0476\n","Precision using CNN and Logistic Regression is :  61.8333\n","Recall using CNN and Logistic Regression is :  76.6667\n","F1 Score using CNN and Logistic Regression is :  66.6537\n"]}],"source":["ans = measure(log, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"uSFe5pgWwfRH"},"source":["**Condensed Nearest Neighbor using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yluz43DpwIdq"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":740,"status":"ok","timestamp":1638173863560,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"8f6ODRr31TBm","outputId":"104143bf-8294-4da5-defc-caf8f7f95611"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and Decision Tree is :  58.8095\n","Precision using CNN and Decision Tree is :  58.5\n","Recall using CNN and Decision Tree is :  56.6667\n","F1 Score using CNN and Decision Tree is :  60.7143\n"]}],"source":["ans = measure(clf, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"7gMLBmgckxAZ"},"source":["**Condensed Nearest Neighbor using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L9ae3fGUwehO"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678,"status":"ok","timestamp":1638173867999,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"K23C1iKO11T3","outputId":"7cef7048-eb55-4356-92b9-b1284e8fc04b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and SVM is :  51.4286\n","Precision using CNN and SVM is :  52.8571\n","Recall using CNN and SVM is :  95.0\n","F1 Score using CNN and SVM is :  67.697\n"]}],"source":["ans = measure(cl, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"1R8GSajjlK_7"},"source":["**Condensed Nearest Neighbor using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xoHOl7ekwYN"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1638173873787,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"NLCBQix-2ANs","outputId":"0b97d373-abd2-4840-db2a-9cba7fd5fc49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and Naive Bayes is :  54.2857\n","Precision using CNN and Naive Bayes is :  52.1667\n","Recall using CNN and Naive Bayes is :  52.5\n","F1 Score using CNN and Naive Bayes is :  50.7143\n"]}],"source":["ans = measure(gnb, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"SI5R4ugOllN9"},"source":["**Condensed Nearest Neighbor using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xK-gPQDQlI-H"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7047,"status":"ok","timestamp":1638173884028,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"TB2Hq6xm2PY7","outputId":"918488b5-6c9c-4f4b-fd6f-273f0ede098d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and Random Forest is :  63.0952\n","Precision using CNN and Random Forest is :  70.881\n","Recall using CNN and Random Forest is :  62.5\n","F1 Score using CNN and Random Forest is :  63.2489\n"]}],"source":["ans = measure(rf, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"y0TLcfGdl5FS"},"source":["**Condensed Nearest Neighbor using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbzRInC5ljnY"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":913,"status":"ok","timestamp":1638173887088,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"PLCW-jVg2cj-","outputId":"50ab4605-527a-4558-c27b-8a4221f67e74"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using CNN and KNN is :  49.5238\n","Precision using CNN and KNN is :  47.7857\n","Recall using CNN and KNN is :  53.3333\n","F1 Score using CNN and KNN is :  48.7381\n"]}],"source":["ans = measure(knn, x_condense, y_condense)\n","\n","print(\"Acuracy using CNN and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using CNN and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using CNN and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using CNN and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"UEECNUtkl833"},"source":["# **Random Over Sampling with Imblearn**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsPsfr3Il4U5"},"outputs":[],"source":["from imblearn.over_sampling import RandomOverSampler\n","\n","ros = RandomOverSampler(random_state=42)\n","x_ros, y_ros = ros.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1638173896432,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"lMcaWK4MmGbJ","outputId":"235818e2-f308-44c8-b419-41f3e02fd7a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape Counter({1: 70, 0: 31})\n","Resample dataset shape Counter({1: 70, 0: 70})\n"]}],"source":["print('Original dataset shape', Counter(y))\n","print('Resample dataset shape', Counter(y_ros))"]},{"cell_type":"markdown","metadata":{"id":"aEh-z-XDmZYx"},"source":["**Random Over sampling with Imblearn**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V_O_3jgymI_W"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2053,"status":"ok","timestamp":1638173904427,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"Ws5v9V3y3RQl","outputId":"52610e6b-62ac-4ca6-cb0a-d497f3e805cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearn and Logistic Regression is :  70.0\n","Precision using Random Oversampling - Imblearn and Logistic Regression is :  70.9524\n","Recall using Random Oversampling - Imblearn and Logistic Regression is :  65.7143\n","F1 Score using Random Oversampling - Imblearn and Logistic Regression is :  66.6804\n"]}],"source":["ans = measure(log, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearn and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"MOEL9_NhmwY9"},"source":["**Random Over Sampling using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cu-J5uiEmYrv"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2271,"status":"ok","timestamp":1638173913820,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"vq_Qduje39QA","outputId":"48fe6550-7ac4-435a-bef2-0de68ee17659"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearn and Decision Tree is :  78.5714\n","Precision using Random Oversampling - Imblearn and Decision Tree is :  91.8929\n","Recall using Random Oversampling - Imblearn and Decision Tree is :  72.8571\n","F1 Score using Random Oversampling - Imblearn and Decision Tree is :  76.2214\n"]}],"source":["ans = measure(clf, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearn and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"k8nUnbNEnFSK"},"source":["**Random Over Sampling using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_W8PYXRhmubi"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1638173917649,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"zsPNvkl84Gdn","outputId":"2105fc49-e2e0-496c-ea09-6e59bec549a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearnand SVM is :  65.7143\n","Precision using Random Oversampling - Imblearn and SVM is :  62.8398\n","Recall using Random Oversampling - Imblearn and SVM is :  72.8571\n","F1 Score using Random Oversampling - Imblearn and SVM is :  66.3875\n"]}],"source":["ans = measure(cl, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearnand SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"jfXlMuG8nIrw"},"source":["**Random Over Sampling using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fh3BsuJAnEDS"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1638173923266,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"_rdbVjDn4L0u","outputId":"19faa0c3-ac05-496e-e037-ca0a93895544"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearn and Naive Bayes is :  80.7143\n","Precision using Random Oversampling - Imblearn and Naive Bayes is :  92.1429\n","Recall using Random Oversampling - Imblearn and Naive Bayes is :  67.1429\n","F1 Score using Random Oversampling - Imblearn and Naive Bayes is :  75.7862\n"]}],"source":["ans = measure(gnb, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearn and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"rLUoTdqfnpp7"},"source":["**Random Over Sampling using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KprapsjunbGT"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9223,"status":"ok","timestamp":1638173937068,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"rpmV97bn4T8M","outputId":"59393190-7630-4e6c-f950-1f449270bbfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearn and Random Forest is :  87.1429\n","Precision using Random Oversampling - Imblearn and Random Forest is :  93.3333\n","Recall using Random Oversampling - Imblearn and Random Forest is :  81.4286\n","F1 Score using Random Oversampling - Imblearn and Random Forest is :  86.0932\n"]}],"source":["ans = measure(rf, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearn and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"BiOIPuE0n69o"},"source":["**Random Over Sampling using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIuw6SqEnpEH"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1223,"status":"ok","timestamp":1638173944112,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"to2munr34X7x","outputId":"0eed346f-5f0b-4283-fd84-8b5855daf89a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Oversampling - Imblearn and KNN is :  70.0\n","Precision using Random Oversampling - Imblearn and KNN is :  76.1569\n","Recall using Random Oversampling - Imblearn and KNN is :  65.7143\n","F1 Score using Random Oversampling - Imblearn and KNN is :  66.837\n"]}],"source":["ans = measure(knn, x_ros, y_ros)\n","\n","print(\"Acuracy using Random Oversampling - Imblearn and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Oversampling - Imblearn and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Oversampling - Imblearn and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Oversampling - Imblearn and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"7eVB09b3oELP"},"source":["# **Near Miss**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY9uEIfOn6GG"},"outputs":[],"source":["from imblearn.under_sampling import NearMiss\n","\n","nm = NearMiss()\n","x_nm, y_nm = nm.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1638173947046,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"KY8ZwdsaoIMw","outputId":"e4b3d395-1cf0-46d1-c3b6-f64f15f6c18f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape: Counter({0: 31, 1: 31})\n"]}],"source":["print('Original dataset shape:', Counter(y))\n","print('Resample dataset shape:', Counter(y_nm))"]},{"cell_type":"markdown","metadata":{"id":"emz0vWfWodOy"},"source":["**Near Miss using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Iomyb4NoMTH"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1375,"status":"ok","timestamp":1638173952830,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"lNQoKNpd4_wv","outputId":"23945063-ff33-461c-d946-0dfbfeab9a0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and Logistic Regression is :  62.8571\n","Precision using Near Miss and Logistic Regression is :  63.6667\n","Recall using Near Miss and Logistic Regression is :  67.5\n","F1 Score using Near Miss and Logistic Regression is :  64.2619\n"]}],"source":["ans = measure(log, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"VBqOjMyqoipt"},"source":["**Near Miss using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZCL2u4lXochf"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1539,"status":"ok","timestamp":1638173954987,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"-nSbDHVy5sKB","outputId":"956af16e-db21-4f39-a37e-16579555d870"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and Decision Tree is :  55.9524\n","Precision using Near Miss and Decision Tree is :  52.5\n","Recall using Near Miss and Decision Tree is :  55.0\n","F1 Score using Near Miss and Decision Tree is :  50.4286\n"]}],"source":["ans = measure(clf, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"cznWHmqqpFjd"},"source":["**Near Miss using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NusDgA3Jo0O5"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1072,"status":"ok","timestamp":1638173972495,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"nfsgOLfr5wCJ","outputId":"584a55e9-7346-4718-a45d-0c04948d92bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and SVM is :  61.1905\n","Precision using Near Miss and SVM is :  58.1667\n","Recall using Near Miss and SVM is :  84.1667\n","F1 Score using Near Miss and SVM is :  68.3333\n"]}],"source":["ans = measure(cl, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"p_5aZb-epaH6"},"source":["**Near Miss using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uuCK23m4pEm1"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1138,"status":"ok","timestamp":1638173978385,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"rygPy14s50g8","outputId":"05ac8d94-7857-40d1-923f-ccb534a6e557"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and Naive Bayes is :  62.381\n","Precision using Near Miss and Naive Bayes is :  59.3333\n","Recall using Near Miss and Naive Bayes is :  64.1667\n","F1 Score using Near Miss and Naive Bayes is :  59.4048\n"]}],"source":["ans = measure(gnb, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"lXw2M53wpriN"},"source":["**Near Miss using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MOvlVPxYpZHm"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7039,"status":"ok","timestamp":1638173990817,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"1veSE0jR54-v","outputId":"299f3609-100a-4b73-ee4a-bd15188cf731"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and Random Forest is :  72.381\n","Precision using Near Miss and Random Forest is :  73.5\n","Recall using Near Miss and Random Forest is :  74.1667\n","F1 Score using Near Miss and Random Forest is :  71.381\n"]}],"source":["ans = measure(rf, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"VUTeri4Tp8ox"},"source":["**Near Miss using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TA_Hd7JQpqth"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1202,"status":"ok","timestamp":1638173996971,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"WremTO_35_fN","outputId":"b93dfdef-fa74-405d-9a97-61e13ad0d50c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Near Miss and KNN is :  53.5714\n","Precision using Near Miss and KNN is :  52.5\n","Recall using Near Miss and KNN is :  72.5\n","F1 Score using Near Miss and KNN is :  60.0\n"]}],"source":["ans = measure(knn, x_nm, y_nm)\n","\n","print(\"Acuracy using Near Miss and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Near Miss and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Near Miss and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Near Miss and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"2EePFcy8qByT"},"source":["# **Random Under Sampling using One Sided Selection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4YRmWzRp7iB"},"outputs":[],"source":["from imblearn.under_sampling import OneSidedSelection\n","\n","undersample = OneSidedSelection(n_neighbors=1, n_seeds_S=200)\n","x_oss, y_oss = undersample.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1638174000726,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"8fgB3hxOqO88","outputId":"3455028c-d298-4d95-f162-8a20971ec41f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape: Counter({1: 199, 0: 31})\n"]}],"source":["print('Original dataset shape:', Counter(y))\n","print('Resample dataset shape:', Counter(y_oss))"]},{"cell_type":"markdown","metadata":{"id":"SrxGg2oMqkGI"},"source":["**Random Undersampling using One Sided Selection with Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8HtKx_QWqSY3"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1736,"status":"ok","timestamp":1638174013771,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"Hzgm4hEY6uJn","outputId":"2c9352f0-7bcf-4a31-e325-6bc9a0a0ce81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and Logistic Regression is :  86.5217\n","Precision using Random Undersampling using One Sided Selection and Logistic Regression is :  86.5217\n","Recall using Random Undersampling using One Sided Selection and Logistic Regression is :  100.0\n","F1 Score using Random Undersampling using One Sided Selection and Logistic Regression is :  92.7685\n"]}],"source":["ans = measure(log, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"WssNrRiBrFIN"},"source":["**Random Undersampling using One Sided Selection and Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_LJyExmqjQD"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2590,"status":"ok","timestamp":1638174038206,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"zH2SVcU961gi","outputId":"202bf808-cfdd-4112-f24e-94faf2df2080"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and Decision Tree is :  91.3043\n","Precision using Random Undersampling using One Sided Selection and Decision Tree is :  91.2909\n","Recall using Random Undersampling using One Sided Selection and Decision Tree is :  99.0\n","F1 Score using Random Undersampling using One Sided Selection and Decision Tree is :  94.9688\n"]}],"source":["ans = measure(clf, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"BHe827Xwrcl2"},"source":["**Random Undersampling using One Sided Selection and SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Top1u0dkrD8n"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1610,"status":"ok","timestamp":1638174039799,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"LulBDi3h6-YT","outputId":"49193002-0eae-4285-8d7a-7435a246d096"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and SVM is :  86.5217\n","Precision using Random Undersampling using One Sided Selection and SVM is :  86.5217\n","Recall using Random Undersampling using One Sided Selection and SVM is :  100.0\n","F1 Score using Random Undersampling using One Sided Selection and SVM is :  92.7685\n"]}],"source":["ans = measure(cl, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"EdEcsOLgrzWA"},"source":["**Random Undersampling using One Sided Selection and Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEs1Ljj8rarg"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1909,"status":"ok","timestamp":1638174055120,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"2eGHSwG-7DoV","outputId":"61570f79-7164-40f3-f39e-ea338043ac90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and Naive Bayes is :  72.1739\n","Precision using Random Undersampling using One Sided Selection and Naive Bayes is :  91.8879\n","Recall using Random Undersampling using One Sided Selection and Naive Bayes is :  74.3684\n","F1 Score using Random Undersampling using One Sided Selection and Naive Bayes is :  81.8216\n"]}],"source":["ans = measure(gnb, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"FpPM2oolsWCW"},"source":["**Random Undersampling using One Sided Selection with Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wn8_8BttryXd"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11002,"status":"ok","timestamp":1638174075424,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"xWm6CQ117NRg","outputId":"968f0b26-47b5-49ec-d4e9-46371b55376a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and Random Forest is :  87.8261\n","Precision using Random Undersampling using One Sided Selection and Random Forest is :  88.0397\n","Recall using Random Undersampling using One Sided Selection and Random Forest is :  99.5\n","F1 Score using Random Undersampling using One Sided Selection and Random Forest is :  93.3982\n"]}],"source":["ans = measure(rf, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"sQCbZvAWsvDA"},"source":["**Random Under Sampling using One Sided Selection with KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_I5bBH8sUaQ"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1676,"status":"ok","timestamp":1638174092861,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"ON_GqCM37UZb","outputId":"93d65b58-7b5f-4a4a-911f-4f6a91b934cb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Random Undersampling using One Sided Selection and KNN is :  86.9565\n","Precision using Random Undersampling using One Sided Selection and KNN is :  87.269\n","Recall using Random Undersampling using One Sided Selection and KNN is :  99.5\n","F1 Score using Random Undersampling using One Sided Selection and KNN is :  92.956\n"]}],"source":["ans = measure(knn, x_oss, y_oss)\n","\n","print(\"Acuracy using Random Undersampling using One Sided Selection and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Random Undersampling using One Sided Selection and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Random Undersampling using One Sided Selection and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Random Undersampling using One Sided Selection and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"rpvieWi5upiZ"},"source":["# **Instance Hardness Threshold**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUm2Sm0LtcOl"},"outputs":[],"source":["from imblearn.under_sampling import InstanceHardnessThreshold\n","\n","iht = InstanceHardnessThreshold(random_state = 0)\n","x_iht, y_iht = iht.fit_resample(X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1638174099547,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"ET88GpBIu0gg","outputId":"7c1c3307-8a0e-4367-af4c-d4271fe8a3fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape: Counter({1: 32, 0: 31})\n"]}],"source":["print('Original dataset shape:', Counter(y))\n","print('Resample dataset shape:', Counter(y_iht))"]},{"cell_type":"markdown","metadata":{"id":"KgEIUozBu5IA"},"source":["**Instance Hardness Threshold using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"joI3Shgfu3sz"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2164,"status":"ok","timestamp":1638174107809,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"NQIyofcY8KHz","outputId":"8d026645-43c3-4fdc-eccc-28837da66c70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and Logistic Regression is :  72.381\n","Precision using Instance Hardness Threshold and Logistic Regression is :  75.0\n","Recall using Instance Hardness Threshold and Logistic Regression is :  73.3333\n","F1 Score using Instance Hardness Threshold and Logistic Regression is :  71.4524\n"]}],"source":["ans = measure(log, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"QNpHOQ4CvOTu"},"source":["**Instance Hardness Threshold using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbm63aDNvNXT"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1080,"status":"ok","timestamp":1638174114083,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"2YQZN2cz8NwF","outputId":"826e39d9-d4c2-4ad9-aa30-b03eae77193d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and Decision Tree is :  77.619\n","Precision using Instance Hardness Threshold and Decision Tree is :  82.0\n","Recall using Instance Hardness Threshold and Decision Tree is :  82.5\n","F1 Score using Instance Hardness Threshold and Decision Tree is :  81.2381\n"]}],"source":["ans = measure(clf, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"_Rsy4SKsvgN9"},"source":["**Instance Hardness Threshold using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nn5McAzVvfB2"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1320,"status":"ok","timestamp":1638174129954,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"Qs6aD0528R_v","outputId":"35d59ef6-8cd4-4108-f78c-50e864784f66"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and SVM is :  70.4762\n","Precision using Instance Hardness Threshold and SVM is :  69.5\n","Recall using Instance Hardness Threshold and SVM is :  82.5\n","F1 Score using Instance Hardness Threshold and SVM is :  72.5\n"]}],"source":["ans = measure(cl, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"H7Mf4_mPv0vq"},"source":["**Instance Hardness Threshold using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znFVBnsyvx-v"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1357,"status":"ok","timestamp":1638174136463,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"zZT0-m1-8YxQ","outputId":"7311270f-55b9-4301-a233-d4a2b7483e0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and Naive Bayes is :  66.1905\n","Precision using Instance Hardness Threshold and Naive Bayes is :  71.6667\n","Recall using Instance Hardness Threshold and Naive Bayes is :  60.8333\n","F1 Score using Instance Hardness Threshold and Naive Bayes is :  62.1429\n"]}],"source":["ans = measure(gnb, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"s2HLInSZwHZp"},"source":["**Instance Hardness Threshold using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JErVkPrgwFME"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7620,"status":"ok","timestamp":1638174150788,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"zas80Pxs8bzp","outputId":"eb735fb4-4b3d-43b1-9b2c-7184152508a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and Random Forest is :  73.5714\n","Precision using Instance Hardness Threshold and Random Forest is :  74.3333\n","Recall using Instance Hardness Threshold and Random Forest is :  79.1667\n","F1 Score using Instance Hardness Threshold and Random Forest is :  74.0476\n"]}],"source":["ans = measure(rf, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"RIQ3kAcDwgXv"},"source":["**Instance Hardness Threshold using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h58Bx7srwbwI"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1560,"status":"ok","timestamp":1638174155623,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"kLPWttkV8hRd","outputId":"4afc5b79-0ba6-4cb8-e6b5-531e3e04c5ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using Instance Hardness Threshold and KNN is :  70.2381\n","Precision using Instance Hardness Threshold and KNN is :  69.1667\n","Recall using Instance Hardness Threshold and KNN is :  81.6667\n","F1 Score using Instance Hardness Threshold and KNN is :  71.9841\n"]}],"source":["ans = measure(knn, x_iht, y_iht)\n","\n","print(\"Acuracy using Instance Hardness Threshold and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using Instance Hardness Threshold and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using Instance Hardness Threshold and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using Instance Hardness Threshold and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"DKHvnWdFxFfz"},"source":["# **ADASYN Over Sampling Technique**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_ZLLnaXwx3g"},"outputs":[],"source":["from imblearn.over_sampling import ADASYN\n","\n","x_adasyn, y_adasyn = ADASYN().fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1638174163316,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"l9IFLWsBxCi3","outputId":"9619d9bf-390e-4554-f478-470c3342d047"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape: Counter({1: 70, 0: 65})\n"]}],"source":["print('Original dataset shape:', Counter(y))\n","print('Resample dataset shape:', Counter(y_adasyn))"]},{"cell_type":"markdown","metadata":{"id":"CIOFSZFxxdnv"},"source":["**ADASYN using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U07rzgHfxE_q"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2163,"status":"ok","timestamp":1638174171177,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"k_oL0Fw48nxD","outputId":"1a3aaf07-1b3d-491f-ac3c-d439a2d0042c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and Logistic Regression is :  66.7582\n","Precision using ADASYN and Logistic Regression is :  67.6389\n","Recall using ADASYN and Logistic Regression is :  67.1429\n","F1 Score using ADASYN and Logistic Regression is :  66.2663\n"]}],"source":["ans = measure(log, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"IR-qZ4Q9xk4S"},"source":["**ADASYN using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OtuU3fwxcPr"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2147,"status":"ok","timestamp":1638174176789,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"uR_pSnHC9Wt0","outputId":"49d23bef-85c4-4014-e4cb-3796c06db87b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and Decision Tree is :  77.3077\n","Precision using ADASYN and Decision Tree is :  77.996\n","Recall using ADASYN and Decision Tree is :  74.2857\n","F1 Score using ADASYN and Decision Tree is :  74.8498\n"]}],"source":["ans = measure(clf, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"8N97-j24x6up"},"source":["**ADASYN using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yBXBf8dx5f-"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1638174182445,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"yPSt7ArT9axE","outputId":"8ee44ab4-32f3-4517-8247-3744dedb125f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and SVM is :  63.5714\n","Precision using ADASYN and SVM is :  62.1468\n","Recall using ADASYN and SVM is :  71.4286\n","F1 Score using ADASYN and SVM is :  65.757\n"]}],"source":["ans = measure(cl, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"vk2WjaXTyPDN"},"source":["**ADASYN using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"777A11dlyMa_"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1085,"status":"ok","timestamp":1638174188777,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"DahdOVev9fBs","outputId":"dbee9bbc-d3ff-4b7e-8be7-f82236f57666"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and Naive Bayes is :  83.0769\n","Precision using ADASYN and Naive Bayes is :  98.3333\n","Recall using ADASYN and Naive Bayes is :  68.5714\n","F1 Score using ADASYN and Naive Bayes is :  79.2028\n"]}],"source":["ans = measure(gnb, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"HgHJSAuxyhQu"},"source":["**ADASYN using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjK2sBaVyfkW"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9307,"status":"ok","timestamp":1638174205660,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"39VlSF239jcD","outputId":"0e776501-cb48-45b2-b07f-8b7a89835351"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and Random Forest is :  83.7363\n","Precision using ADASYN and Random Forest is :  88.869\n","Recall using ADASYN and Random Forest is :  80.0\n","F1 Score using ADASYN and Random Forest is :  82.8755\n"]}],"source":["ans = measure(rf, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"NYzLdxcXy9zb"},"source":["**ADASYN using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8-4BSMyyuvn"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1972,"status":"ok","timestamp":1638174240998,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"krDnNrHz9nDX","outputId":"0f6680d4-2a2f-4cc5-d8c7-9b9eccf08650"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using ADASYN and KNN is :  70.4945\n","Precision using ADASYN and KNN is :  73.2738\n","Recall using ADASYN and KNN is :  57.1429\n","F1 Score using ADASYN and KNN is :  62.5261\n"]}],"source":["ans = measure(knn, x_adasyn, y_adasyn)\n","\n","print(\"Acuracy using ADASYN and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using ADASYN and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ADASYN and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ADASYN and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"kMjy9OkvzOvD"},"source":["# **ENN Under Sampling**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A69hZHxTy8xI"},"outputs":[],"source":["from imblearn.combine import SMOTEENN\n","from imblearn.under_sampling import EditedNearestNeighbours\n","\n","resample=SMOTEENN(enn=EditedNearestNeighbours(sampling_strategy='all'))\n","x_enn, y_enn = resample.fit_resample(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1638174248015,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"7k8xi3RezNBn","outputId":"bc927433-f165-4043-cc54-6bf39c22eb8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataset shape: Counter({1: 70, 0: 31})\n","Resample dataset shape: Counter({0: 46, 1: 24})\n"]}],"source":["print('Original dataset shape:', Counter(y))\n","print('Resample dataset shape:', Counter(y_enn))"]},{"cell_type":"markdown","metadata":{"id":"yRu1Gsozziog"},"source":["**ENN Undersampling using Logistic Regression**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRTR6z-UzTm1"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","log = LogisticRegression(random_state = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1598,"status":"ok","timestamp":1638174258207,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"wPrptRW_-18e","outputId":"4bf82bfc-72a6-4a7c-f4a9-decf9bde3fb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ENN and Logistic Regression is :  85.7143\n","Precision using ENN and Logistic Regression is :  90.0\n","Recall using ENN and Logistic Regression is :  65.0\n","F1 Score using ENN and Logistic Regression is :  73.6667\n"]}],"source":["ans = measure(log, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN and Logistic Regression is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and Logistic Regression is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and Logistic Regression is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and Logistic Regression is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"XJ9czy85zmzr"},"source":["**ENN Undersampling using Decision Tree**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"biltjb-TziDp"},"outputs":[],"source":["from sklearn import tree\n","clf = tree.DecisionTreeClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1161,"status":"ok","timestamp":1638174268246,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"JREQp2yb-542","outputId":"d77d62ad-70a5-487d-c3fb-b4a3f678923e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ENN  and Decision Tree is :  88.5714\n","Precision using ENN and Decision Tree is :  91.6667\n","Recall using ENN and Decision Tree is :  83.3333\n","F1 Score using ENN and Decision Tree is :  89.6667\n"]}],"source":["ans = measure(clf, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN  and Decision Tree is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and Decision Tree is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and Decision Tree is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and Decision Tree is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"W7h9cMqEz36E"},"source":["**ENN Undersampling using SVM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KhhOk40Qz2Lx"},"outputs":[],"source":["from sklearn import svm\n","cl = svm.SVC()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1664,"status":"ok","timestamp":1638174306747,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"fl1bcL-e--GU","outputId":"67a78a22-29d2-4d68-d697-cc49d8e45316"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using ENN and SVM is :  80.0\n","Precision using ENN and SVM is :  80.0\n","Recall using ENN and SVM is :  50.0\n","F1 Score using ENN and SVM is :  59.0\n"]}],"source":["ans = measure(cl, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN and SVM is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and SVM is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and SVM is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and SVM is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"tjcoBbY50M27"},"source":["**ENN Undersampling using Naive Bayes**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJ5Nmpmq0KoM"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","gnb = GaussianNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1638174319729,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"USVGxC9B_CPu","outputId":"12972fdf-b9bb-4830-8753-67cfd8c9edf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ENN and Naive Bayes is :  85.7143\n","Precision using ENN and Naive Bayes is :  89.1667\n","Recall using ENN and Naive Bayes is :  66.6667\n","F1 Score using ENN and Naive Bayes is :  73.5714\n"]}],"source":["ans = measure(gnb, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN and Naive Bayes is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and Naive Bayes is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and Naive Bayes is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and Naive Bayes is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Fm8jA7sd0b2A"},"source":["**ENN Undersampling using Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8ljDp9o0bCD"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7494,"status":"ok","timestamp":1638174338866,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"eT6Bu33i_Gwg","outputId":"203297c1-5767-4e60-81d1-11281223aea0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Acuracy using ENN and Random Forest is :  94.2857\n","Precision using ENN and Random Forest is :  100.0\n","Recall using ENN and Random Forest is :  83.3333\n","F1 Score using ENN and Random Forest is :  89.3333\n"]}],"source":["ans = measure(rf, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN and Random Forest is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and Random Forest is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and Random Forest is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and Random Forest is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"YNsCxtNN0rpN"},"source":["**ENN Undersampling using KNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lm73E1Bx0q3H"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1799,"status":"ok","timestamp":1638174352587,"user":{"displayName":"selvi chandran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnW9xwirhgSwD6LBH7EHjmjnfzb0DKoZ2IXmmJ=s64","userId":"02988708281786665855"},"user_tz":-330},"id":"FMpfFqbI_LLf","outputId":"6b4683ef-182e-4182-9a94-d3409f76c0c5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Acuracy using ENN and KNN is :  85.7143\n","Precision using ENN and KNN is :  90.0\n","Recall using ENN and KNN is :  56.6667\n","F1 Score using ENN and KNN is :  67.6667\n"]}],"source":["ans = measure(knn, x_enn, y_enn)\n","\n","print(\"Acuracy using ENN and KNN is : \",round(ans[0]*100,4))\n","print(\"Precision using ENN and KNN is : \",round(ans[1]*100,4))\n","\n","print(\"Recall using ENN and KNN is : \",round(ans[2]*100,4))\n","print(\"F1 Score using ENN and KNN is : \",round(ans[3]*100,4))"]},{"cell_type":"markdown","metadata":{"id":"Z-z4my-Cz8x7"},"source":["# New Section"]},{"cell_type":"markdown","metadata":{"id":"oe0v6Mpdbgwx"},"source":["**From the above Resampling techniques, We can see that INSTANCE HARDNESS THRESHOLD yields better results than any other techniques**\n","\n","\n","**So, Now taking the INSTANCE HARDNESS THRESHOLD as the resampling technique, we apply different FEATURE SELECTION METHODS and generate comparative analysis among them**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5GUMss-05eo"},"outputs":[],"source":["x_iht"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dd71necmGqyG"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"FYP_Resampling_Techniques (1).ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}